{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRKALN_001',\n",
       " 'CRKALN_002',\n",
       " 'CRKALN_003',\n",
       " 'CRKALN_004',\n",
       " 'CRKALN_005',\n",
       " 'CRKALN_006',\n",
       " 'CRKALN_007',\n",
       " 'CRKALN_008',\n",
       " 'CRKALN_009',\n",
       " 'CRKALN_010']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prepare_data import listTurbines\n",
    "\n",
    "\n",
    "turbines = listTurbines()\n",
    "turbines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297360, 720, 26)\n",
      "Index(['avgwindspeed', 'avgpower', 'windspeedstandarddeviation',\n",
      "       'nacelleposition', 'avgwinddirection', 'availablepowerpublished',\n",
      "       'avgrotorspeed', 'avgpitchangle', 'avgreactivepower',\n",
      "       'ambienttemperature', 'avghumidity', 'turbinepressure', 'density',\n",
      "       'latitude', 'longitude', 'cutoutwindspeed', 'ratedwindspeed',\n",
      "       'rotordiameter', 'hubheight', 'groundlevelaltitude', 'turbulent',\n",
      "       'underperformanceprobability', 'overperformanceprobability',\n",
      "       'turbulentvalid', 'underperformanceprobabilityvalid',\n",
      "       'overperformanceprobabilityvalid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from prepare_data import TurbineData\n",
    "\n",
    "\n",
    "turbineData = TurbineData(turbines[1], verbose=True)\n",
    "print(turbineData.data3d.shape)\n",
    "print(turbineData.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idPower = turbineData.getIdOfColumn(\"avgpower\")\n",
    "idWind = turbineData.getIdOfColumn(\"avgwindspeed\")\n",
    "\n",
    "idPower, idWind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: 20628\n",
      "Not underperform: 102565\n",
      "Normal: 10528\n"
     ]
    }
   ],
   "source": [
    "normalIndices = turbineData.getNormalIndices(maxConsecutiveInvalid=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4652 1162\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 17\n",
    "TEST_RATIO = 0.2\n",
    "\n",
    "\n",
    "# suffle data\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(normalIndices)\n",
    "\n",
    "# split data\n",
    "n_test = int(len(normalIndices) * TEST_RATIO)\n",
    "testIndices = normalIndices[:n_test]\n",
    "trainIndices = normalIndices[n_test:]\n",
    "\n",
    "print(len(trainIndices), len(testIndices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4652, 5)\n",
      "Data shape: (1, 720, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "from cls_dataset import trainTestTurbineDataset\n",
    "\n",
    "\n",
    "targetFeats = [\n",
    "    \"avgwindspeed\",\n",
    "    \"avgpower\",\n",
    "    \"ambienttemperature\",\n",
    "    \"avghumidity\",\n",
    "    \"density\",\n",
    "]\n",
    "targetFeatIndices = [turbineData.getIdOfColumn(feat) for feat in targetFeats]\n",
    "\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "\n",
    "sortedTrainIndices = trainIndices.copy()\n",
    "sortedTrainIndices.sort()  # h5py requires sorted indices\n",
    "\n",
    "scalerTrainData = turbineData.data3d[sortedTrainIndices, 0, :][:, targetFeatIndices]\n",
    "print(scalerTrainData.shape)\n",
    "\n",
    "stdScaler.fit(scalerTrainData)\n",
    "\n",
    "\n",
    "trainSet, testSet = trainTestTurbineDataset(\n",
    "    turbineData.data3d,\n",
    "    trainIndices,\n",
    "    testIndices,\n",
    "    targetFeatIndices,\n",
    "    stdScaler.transform,\n",
    ")\n",
    "\n",
    "print(f\"Data shape: {trainSet[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7871883061049011)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check for nan \n",
    "import numpy as np\n",
    "p\n",
    "np.sum(np.isnan(scalerTrainData)) / np.prod(scalerTrainData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output shape: torch.Size([32, 1, 720, 5])\n",
      "Output shape: torch.Size([32, 1, 717, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from masking import MaskedConv2d\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latentDim):\n",
    "        super().__init__()\n",
    "        self.latentDim = latentDim\n",
    "        # 1 learnable embedding for invalid values\n",
    "        self.maskEmbed = nn.Parameter(torch.zeros(1, 1, 1, 1))\n",
    "        self.conv1 = MaskedConv2d(1, 8, kernel_size=3, stride=2, padding=1)  # 5->3\n",
    "        self.conv2 = MaskedConv2d(8, 16, kernel_size=3, stride=2, padding=1)  # 3->2\n",
    "        self.conv3 = MaskedConv2d(16, 32, kernel_size=2)  # 2->1\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(5728, 2048)\n",
    "        self.fc2 = nn.Linear(2048, latentDim)\n",
    "        \n",
    "        # debug flag\n",
    "        self.debug = 0  # print once\n",
    "    def forward(self, x, mask):\n",
    "        if mask is None:\n",
    "            raise ValueError(\"Mask is required\")\n",
    "        xShapeLen = len(x.shape)\n",
    "        if mask.shape != x.shape[0 : xShapeLen - 1]:\n",
    "            raise ValueError(\n",
    "                \"Mask shape must cover til x's time steps: \"\n",
    "                + str(mask.shape)\n",
    "                + \" != \"\n",
    "                + str(x.shape[0 : xShapeLen - 1])\n",
    "            )\n",
    "\n",
    "        maskAdd1 = mask.unsqueeze(-1).expand_as(x)\n",
    "        x = x * maskAdd1 + (1 - maskAdd1) * self.maskEmbed\n",
    "        \n",
    "        debugging = False\n",
    "        if self.debug > 0:\n",
    "            debugging = True\n",
    "            self.debug -= 1\n",
    "        x, mask = self.conv1(x, mask)\n",
    "        x = torch.relu(x)\n",
    "        if debugging:\n",
    "            print(f\"Conv1: {x.shape}\")\n",
    "        x, mask = self.conv2(x, mask)\n",
    "        x = torch.relu(x)\n",
    "        if debugging:\n",
    "            print(f\"Conv2: {x.shape}\")\n",
    "        x, mask = self.conv3(x, mask)\n",
    "        x = torch.relu(x)\n",
    "        if debugging:\n",
    "            print(f\"Conv3: {x.shape}\")\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latentDim):\n",
    "        super().__init__()\n",
    "        self.latentDim = latentDim\n",
    "        self.fc1 = nn.Linear(latentDim, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 5728)\n",
    "        self.conv1 = nn.ConvTranspose2d(32, 16, kernel_size=2)\n",
    "        self.conv2 = nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1)\n",
    "        self.debug = 0  # print once\n",
    "    def forward(self, x):\n",
    "        debugging = False\n",
    "        if self.debug > 0:\n",
    "            debugging = True\n",
    "            self.debug -= 1\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        if debugging:\n",
    "            print(f\"FC1: {x.shape}\")\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        if debugging:\n",
    "            print(f\"FC2: {x.shape}\")\n",
    "        x = x.view(-1, 32, 179, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        if debugging:\n",
    "            print(f\"Conv1: {x.shape}\")\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        if debugging:\n",
    "            print(f\"Conv2: {x.shape}\")\n",
    "        x = self.conv3(x)\n",
    "        if debugging:\n",
    "            print(f\"Conv3: {x.shape}\")\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "    def forward(self, x, mask=None):\n",
    "        latent = self.encoder(x, mask)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed\n",
    "\n",
    "\n",
    "\n",
    "# test if the model is working\n",
    "testModel = Autoencoder(1024)\n",
    "\n",
    "# pass a random tensor to the model\n",
    "x = torch.randn(32, 1, 720, 5)\n",
    "import numpy as np\n",
    "output = testModel(x, mask=torch.ones(x.shape[:3]))\n",
    "\n",
    "print(f\"Expected output shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# print(x[0])\n",
    "# print(output[0])\n",
    "\n",
    "del testModel\n",
    "del x\n",
    "del output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from masking import maskedMseLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/micromamba/lib/python3.9/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647380992/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X nans: 0.8097222447395325\n",
      "Reconstructs nans: 0.8125\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7493923902511597\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.62109375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6849826574325562\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7469618320465088\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8098090291023254\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8748263716697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8120659589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6111111044883728\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6228298544883728\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8572048544883728\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7957465052604675\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5618055462837219\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7452256679534912\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.745312511920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8120659589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8723958134651184\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8109375238418579\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8080729246139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8110243082046509\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7480902671813965\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8725694417953491\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7497395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9366319179534912\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7354166507720947\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9355034828186035\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8084201216697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8565104007720947\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9347222447395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9345486164093018\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8079861402511597\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8730902671813965\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5601562261581421\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7479166388511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8596354126930237\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7489583492279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8118055462837219\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8088541626930237\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9340277910232544\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8734375238418579\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9357638955116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.808506965637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7329860925674438\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8122395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8089409470558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7440103888511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8101562261581421\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.874913215637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6826388835906982\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9210069179534912\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.858593761920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8608506917953491\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6861110925674438\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8611978888511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7963541746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8119791746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6695312261581421\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7975694537162781\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7951388955116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7356770634651184\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8544270992279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6194444298744202\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9350694417953491\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9212673902511597\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9371528029441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8109375238418579\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.730555534362793\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.812413215637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7352430820465088\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7355034947395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6845486164093018\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9967013597488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9358506798744202\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8735243082046509\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.557812511920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9330729246139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7261284589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9352430701255798\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8727430701255798\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7323784828186035\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9337673783302307\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.807812511920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8091145753860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8119791746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8108506798744202\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9199652671813965\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8052951097488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9356771111488342\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8570312261581421\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7985243201255798\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8590278029441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8717882037162781\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8739583492279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.859375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8729166388511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8571180701255798\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7339409589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8120659589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9815972447395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.871874988079071\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7361978888511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6871528029441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7803819179534912\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.808506965637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8700520992279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8578125238418579\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6700521111488342\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7164062261581421\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7973958253860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6842013597488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8121528029441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8089409470558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7488715052604675\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9346354007720947\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8094618320465088\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9370659589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.936718761920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8716145753860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "Epoch [1/10], Loss: nan\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.746180534362793\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8099826574325562\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7328993082046509\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6863715052604675\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7289062738418579\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6223090291023254\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6704860925674438\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7496528029441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8744791746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9990451335906982\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6848958134651184\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9978298544883728\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7495659589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8747395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8738715052604675\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.733593761920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7463541626930237\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8747395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8576388955116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6235243082046509\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6845486164093018\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7361978888511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6209201216697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8743055462837219\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6700521111488342\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8102430701255798\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.808506965637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.871874988079071\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8114583492279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7466145753860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8111110925674438\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9342013597488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.65625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8580729365348816\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9368923902511597\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7496528029441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9231770634651184\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8092013597488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8123263716697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8120659589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7497395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.687413215637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7459201216697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7965278029441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8591145873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8609374761581421\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7456597089767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9220486283302307\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8730902671813965\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7482638955116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8527777791023254\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6703125238418579\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8581597208976746\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6736111044883728\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6693576574325562\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7498263716697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8090277910232544\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8568576574325562\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7958333492279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6838541626930237\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6793403029441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9339409470558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.749218761920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9769096970558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6831597089767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9318576455116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8730034828186035\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8111979365348816\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8534722328186035\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9221354126930237\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.811718761920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6833333373069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6099826097488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8091145753860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9315103888511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8743055462837219\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.609288215637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9369791746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7975694537162781\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8732638955116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7953993082046509\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8597221970558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9325520992279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9363715052604675\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8714409470558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9359375238418579\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8585069179534912\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8722222447395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9372395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7182291746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8729166388511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9330729246139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9213541746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9334201216697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.80859375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6822916865348816\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9176215529441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.808506965637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6695312261581421\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7322916388511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7458333373069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6228298544883728\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8106771111488342\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6859375238418579\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8726562261581421\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6848958134651184\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7952256798744202\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7479166388511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7455729246139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9348958134651184\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8737847208976746\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9817708134651184\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "Epoch [2/10], Loss: nan\n",
      "X nans: 0.7466145753860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.746180534362793\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8720486164093018\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7497395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7345486283302307\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8721354007720947\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7980034947395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.682812511920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.746006965637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7973958253860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8112847208976746\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8730034828186035\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7322916388511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6075521111488342\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8709201216697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6839409470558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7473958134651184\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8111110925674438\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.871006965637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8543402552604675\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7328993082046509\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9352430701255798\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8739583492279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8705729246139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6844618320465088\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8590278029441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8092013597488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.4969618022441864\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7493055462837219\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9846354126930237\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8090277910232544\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8114583492279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8107638955116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8122395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9352430701255798\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6839409470558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8748263716697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7454861402511597\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9202256798744202\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8076388835906982\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9366319179534912\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9236111044883728\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7324652671813965\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9325520992279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.68359375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9373263716697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8570312261581421\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7328125238418579\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9993923902511597\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7493055462837219\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.808680534362793\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9370659589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7925347089767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.871874988079071\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.749913215637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8080729246139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8730902671813965\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9224826097488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8100694417953491\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6853298544883728\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8120659589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.858593761920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8731771111488342\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7822048664093018\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8716145753860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8725694417953491\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6831597089767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7452256679534912\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9358506798744202\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7454861402511597\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9009548425674438\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7456597089767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8097222447395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7459201216697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9855034947395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8123263716697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.809374988079071\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9990451335906982\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8606770634651184\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8707465529441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9839409589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8727430701255798\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9198784828186035\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9362847208976746\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7972221970558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6859375238418579\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7940104007720947\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7488715052604675\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8120659589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8747395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8107638955116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7473958134651184\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7350694537162781\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8724826574325562\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7941840291023254\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9210069179534912\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8087673783302307\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8730902671813965\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8714409470558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8700520992279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8444444537162781\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6110243201255798\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.800868034362793\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9372395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8591145873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9201388955116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8565972447395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8714409470558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7473090291023254\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8113715052604675\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9858506917953491\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5619791746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9213541746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7973958253860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.49340277910232544\n",
      "Reconstructs nans: 1.0\n",
      "Epoch [3/10], Loss: nan\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8088541626930237\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7473090291023254\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8591145873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7459201216697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8609374761581421\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.808680534362793\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8748263716697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8744791746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.80859375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9197916388511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6552083492279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6698784828186035\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9363715052604675\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7464409470558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.746180534362793\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7487847208976746\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9333333373069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6234375238418579\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8100694417953491\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8057291507720947\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.921093761920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9205729365348816\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8443576097488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6871528029441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6853298544883728\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8097222447395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6096354126930237\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7963541746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5613715052604675\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.934374988079071\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.796788215637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.749913215637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7474826574325562\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8707465529441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9236978888511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8089409470558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7480902671813965\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6860243082046509\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6868055462837219\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7498263716697693\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8713541626930237\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7485243082046509\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7497395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7809895873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7476562261581421\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8107638955116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8585069179534912\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6237847208976746\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8100694417953491\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7471354007720947\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9126735925674438\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8743923902511597\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.796875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.90234375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7489583492279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8701388835906982\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8049479126930237\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7454861402511597\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8706597089767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8092013597488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8108506798744202\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8739583492279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.933506965637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6723958253860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.687413215637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7317708134651184\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9372395873069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7339409589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7470486164093018\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7495659589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9342013597488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6216145753860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8599826097488403\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9201388955116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9983506798744202\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8667534589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.625\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.5619791746139526\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7462673783302307\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6245659589767456\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8740451335906982\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8723090291023254\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8580729365348816\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8605034947395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7436631917953491\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6808159947395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8103298544883728\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7946180701255798\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7450520992279053\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.542881965637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9236111044883728\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8578993082046509\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9346354007720947\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.557812511920929\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8611978888511658\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7965278029441833\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6861110925674438\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8107638955116272\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.749913215637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8091145753860474\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.874913215637207\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6811631917953491\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.7329860925674438\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9347222447395325\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9222221970558167\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8708333373069763\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.75\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.6875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 1.0\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8600694537162781\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.9375\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.8125\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n",
      "X nans: 0.875\n",
      "Reconstructs nans: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     40\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 41\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     44\u001b[0m outputs\u001b[38;5;241m.\u001b[39mappend((num_epochs, x\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu(), reconstructs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()))\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    214\u001b[0m         group,\n\u001b[1;32m    215\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         state_steps,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/torch/optim/adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 784\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/torch/optim/adam.py:430\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    428\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    432\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainLoader = DataLoader(trainSet, batch_size=16, shuffle=True, pin_memory=True)\n",
    "testLoader = DataLoader(testSet, batch_size=16, shuffle=True, pin_memory=True)\n",
    "\n",
    "model = Autoencoder(1024).to(device)\n",
    "criterion = maskedMseLoss\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "outputs = []\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for x, mask in trainLoader:\n",
    "        x, mask = x.float().to(device), mask.float().to(device)\n",
    "\n",
    "        print(f\"X nans: {torch.isnan(x).sum() / x.numel()}\")\n",
    "\n",
    "        # Forward pass\n",
    "        reconstructs = model(x, mask)\n",
    "        \n",
    "        print(f\"Reconstructs nans: {torch.isnan(reconstructs).sum() / reconstructs.numel()}\")\n",
    "        \n",
    "        # match reconstructed shape with inputs\n",
    "        n_timestepsReconstructed = reconstructs.shape[-2]\n",
    "        x = x[:, :, :n_timestepsReconstructed, :]\n",
    "        mask = mask[:, :, :n_timestepsReconstructed]\n",
    "        \n",
    "        loss = criterion(reconstructs, x, mask)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    outputs.append((num_epochs, x.detach().cpu(), reconstructs.detach().cpu()))\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {np.mean(losses):.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"autoencoder_cnn.pth\")\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "# Plotting the last 100 values\n",
    "plt.plot(losses[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(23045), 29320)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedNormalIndices = normalIndices.copy()\n",
    "sortedNormalIndices.sort()  \n",
    "normData = turbineData.data3d[sortedNormalIndices, 0, :][:, targetFeatIndices]\n",
    "np.isnan(normData).sum() , normData.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(41616), 1486800)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData = turbineData.data3d[:, 0, :][:, targetFeatIndices]\n",
    "np.isnan(allData).sum(), allData.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1, 720, 5)\n",
      "55715\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for i in range(16):\n",
    "    x.append(trainSet[i][0])\n",
    "x = np.array(x)\n",
    "\n",
    "print(x.shape)\n",
    "print(np.isnan(x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 720, 5)\n",
      "3600\n"
     ]
    }
   ],
   "source": [
    "# exclude transform and reshape\n",
    "x = []\n",
    "for i in range(1):\n",
    "    i = 200\n",
    "    rowIdx = trainSet.rowIndices[i]\n",
    "    x.append(testSet.turbineData3d[rowIdx][:, targetFeatIndices])\n",
    "x = np.array(x)\n",
    "\n",
    "print(x.shape)\n",
    "print(np.isnan(x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"test.csv\", x[0], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbineData.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
